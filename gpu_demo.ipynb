{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "333fe534",
   "metadata": {},
   "source": [
    "## CNN Attn: GPU Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4764eeb7",
   "metadata": {},
   "source": [
    "### Intro \n",
    "So this notebook is just an example of how to get one of my early audio CNN/ Transformer models onto a GPU. It will include some of my thoughts and issues that I have had to consider. This is an age gender detector from samples of audio from the Monzilla Common Voice Dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b573d6df",
   "metadata": {},
   "source": [
    "##### Import the relavent libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b0de1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import torchaudio.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fa2b12",
   "metadata": {},
   "source": [
    "##### Setup for possible use of the GPU (any serious tuning will require GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43faf286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445b7ee0",
   "metadata": {},
   "source": [
    "### Data\n",
    "This notebook is no connected to live data and the main data and my initial input had been the audio waveforms as pytorch Tensors. These were being transformed into their final form in the Dataset, but this meant the an additional calculation in the loop. The calculation was not too expensive when running on a CPU but an inability to set up the transformation on GPU meant much of the advantage was lost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acde3282",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_specs = torch.load(\"train_waveforms.pt\")\n",
    "dev_specs = torch.load(\"dev_waveforms.pt\")\n",
    "train_ages = torch.load(\"train_ages.pt\")\n",
    "dev_ages = torch.load(\"dev_ages.pt\")\n",
    "train_gens = torch.load(\"train_gens.pt\")\n",
    "dev_gens = torch.load(\"dev_gens.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c186239",
   "metadata": {},
   "source": [
    "After loading, the following code cuts them all down to a 3.8 second time window, transforms the waveforms (sample rate of 32000) to make a 1x128x128. The derivatives of the coefficients are concattenated to the 2nd and 3rd input chanels of the image. Somewhere the resulting tensor must be transferred to device to allow GPU processing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0687979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.MelSpectrogram(sample_rate=32000,n_fft=1900)\n",
    "m = train_waveforms.size(0)\n",
    "test_specs = []\n",
    "for i in range(m):\n",
    "  form = train_waveforms[i,:121600]\n",
    "  x = transform(form).to(device)\n",
    "  x = x[:,:-1] # loosing the 129 on the x axis\n",
    "  delta = F.compute_deltas(x,win_length=7)\n",
    "  delta2 = F.compute_deltas(delta,win_length=7)\n",
    "  cat = torch.cat((x.unsqueeze(0),delta.unsqueeze(0),delta2.unsqueeze(0))).to(device)\n",
    "  test_specs.append(cat.unsqueeze(0))\n",
    "\n",
    "test_specs = torch.cat(test_specs,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa20c5d",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "The Dataset inherits from torch.utils.data.Dataset and requires an \\_\\_init\\_\\_, a \\_\\_getitem\\_\\_, and a \\_\\_len\\_\\_. There is no requirement to do anything fancy here, but it is an opportunity to make sure all tensors are on the GPU. Depending on how you receive the data, the spectrogram transformation can be incorporated into the \\_\\_getitem\\_\\_ method. From a computational and complexity point of view it is better if the the datapoints are already transformed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3e5615",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "  \"\"\"\n",
    "  Creates a pytorch dataset class\n",
    "  inputs Waveforms Tensor, age list, gender list\n",
    "  outputs Pytorch Dataset where [i] 3x128x128 ChannelsxFreqxTime\n",
    "  with C1 mel energies, C2, derivatives, C3 derivatives\n",
    "  \"\"\"\n",
    "  \n",
    "  \n",
    "  def __init__(self, specs, age, gender):\n",
    "    self.waveforms = specs\n",
    "    self.age = torch.LongTensor(age).to(device)\n",
    "    self.gender = torch.LongTensor(gender).to(device)\n",
    "\n",
    "  def __getitem__(self,index):\n",
    "    x = self.waveforms[index]\n",
    "    y = self.age[index]\n",
    "    z = self.gender[index]\n",
    "    \n",
    "    return x,y,z\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.waveforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01899c26",
   "metadata": {},
   "source": [
    "### Model\n",
    "Refer to https://rjnclarke.wixsite.com/rich-clarke for full details of the model. Basically this is a shallow CNN with 2 convolutions of 12 and 30 filters. This shallow structure appears well suited to the audio spectrogram. In addition to this the primary channel of the image is fed into 3 attention heads, as in Attention is all you need. These are the rows of the spectrogram, so the embedding is the coefficient values at each time interval across a given frequency, and each frequency is part of the sequence. The transformer encoder is then interpreting these frequency bands as they relate to each other. The CNN and Attn are simply cocatenated before being fed into a classifier. As there is minimal reduction in CNN or Transformer, the transfer to the Fully conected layer is expensive in terms of parameters. This version has 137,000,000. The model returns a result for the age problem and one for the gender problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42f5fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenderAgeattnModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GenderAgeattnModel, self).__init__()\n",
    "        \n",
    "        # dropouts \n",
    "        self.dropout1 = nn.Dropout(0.10) # important to optimize \n",
    "        self.dropout2 = nn.Dropout(0.15) # important to optimize \n",
    "        \n",
    "        # dense\n",
    "        self.batch1 = nn.BatchNorm2d(3)\n",
    "\n",
    "        self.linear3 = nn.Linear(16384,3000)\n",
    "        \n",
    "        self.batch4 = nn.BatchNorm1d(3000)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.linear4 = nn.Linear(3000,100)\n",
    "        \n",
    "        self.batch5 = nn.BatchNorm1d(100)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.linear_gen = nn.Linear(100,2)\n",
    "        self.linear_age = nn.Linear(100,6)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Attention track \n",
    "        # Head #1\n",
    "        self.mp = nn.MaxPool2d(2) # unused \n",
    "        self.k1 = nn.Linear(128, 128) # input_size, k size\n",
    "        self.v1 = nn.Linear(128, 128) # input_size, v size\n",
    "        self.q1 = nn.Linear(128, 128) # input_size, q_size \n",
    "\n",
    "        # Head #2\n",
    "        self.k2 = nn.Linear(128, 128)\n",
    "        self.v2 = nn.Linear(128, 128)\n",
    "        self.q2 = nn.Linear(128, 128)\n",
    "        \n",
    "        # Head #2\n",
    "        self.k3 = nn.Linear(128, 128)\n",
    "        self.v3 = nn.Linear(128, 128)\n",
    "        self.q3 = nn.Linear(128, 128)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        self.attention_head_projection = nn.Linear(384, 128) #dim_v * 2heads\n",
    "        self.norm_mh = nn.LayerNorm(128)\n",
    "        self.relu_attn = nn.ReLU() # unused \n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batch1(x)  \n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # attn track \n",
    "        ins = x[:,0,:,:]\n",
    "        \n",
    "        # Attention Head 1\n",
    "        qs1 = self.q1(ins)\n",
    "        ks1 = self.k1(ins)\n",
    "        vs1 = self.v1(ins)\n",
    "        sims_1 = torch.bmm(qs1,torch.transpose(ks1,1,2))/ np.sqrt(64)\n",
    "        soft_1 = self.softmax(sims_1)\n",
    "        weighted_1 = torch.bmm(soft_1,vs1)\n",
    "        \n",
    "        # Attention Head 2\n",
    "        qs2 = self.q2(ins)\n",
    "        ks2 = self.k2(ins)\n",
    "        vs2 = self.v2(ins)\n",
    "        sims_2 = torch.bmm(qs2,torch.transpose(ks2,1,2))/ np.sqrt(64)\n",
    "        soft_2 = self.softmax(sims_2)\n",
    "        weighted_2 = torch.bmm(soft_2,vs2) # B x 128 x 128\n",
    "        \n",
    "        \n",
    "        # Attention Head 3\n",
    "        qs3 = self.q3(ins)\n",
    "        ks3 = self.k3(ins)\n",
    "        vs3 = self.v3(ins)\n",
    "        sims_3 = torch.bmm(qs3,torch.transpose(ks3,1,2))/ np.sqrt(64)\n",
    "        soft_3 = self.softmax(sims_3)\n",
    "        weighted_3 = torch.bmm(soft_3,vs3)\n",
    "    \n",
    "        # concat attn heads and project \n",
    "        concat = torch.cat((weighted_1,weighted_2,weighted_3),dim=2) #B x 128 x 384 \n",
    "        projected = self.attention_head_projection(concat) # B x 128 x 128\n",
    "        normed = self.norm_mh(projected) # B x 128 x 128\n",
    "        out_attn = self.relu_attn(normed)\n",
    "        out_attn = out_attn.view(-1,16384) # B x 16384\n",
    "        \n",
    "        # dense   \n",
    "        full = self.dropout2(out_attn)\n",
    "        x = self.linear3(full)\n",
    "        \n",
    "        #Bx3000\n",
    "        \n",
    "        x = self.batch4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.linear4(x)\n",
    "        \n",
    "        #Bx100\n",
    "        \n",
    "        \n",
    "        x = self.batch5(x)\n",
    "        x = self.relu5(x)\n",
    "        gen = self.linear_gen(x) # B x 6\n",
    "        age = self.linear_age(x) # B x 2 \n",
    "\n",
    "        return gen, age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d88c17c",
   "metadata": {},
   "source": [
    "keep track of accuracy (to go back to numpy the tensors must be on CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaffff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out_age,out_gen, target_age,target_gen):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    batch_size = target_age.shape[0]\n",
    "\n",
    "    _, pred_age = torch.max(out_age, dim=-1)\n",
    "    _,pred_gen = torch.max(out_gen,dim=1)\n",
    "    pred_age = np.array(pred_age.to(\"cpu\"))\n",
    "    pred_gen = np.array(pred_gen.to(\"cpu\"))\n",
    "    target_age = np.array(target_age.to(\"cpu\"))\n",
    "    target_gen = np.array(target_gen.to(\"cpu\"))\n",
    "    \n",
    "    correct_age = pred_age == target_age \n",
    "    correct_gen = pred_gen == target_gen\n",
    "    correct = correct_age == correct_gen\n",
    "    \n",
    "    acc = np.sum(correct) / batch_size\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98a7807",
   "metadata": {},
   "source": [
    "### Training function\n",
    "This will be taking two loss functions, one for each problem. The weighting between these is another hyper parameter to consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a43a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, data_loader, model, optimizer, criterion_age,criterion_gender,gen_weight=0.5):\n",
    "        \n",
    "    running_loss = []\n",
    "    running_acc = []\n",
    "    run_ind = 0\n",
    "    total_acc = 0\n",
    "    total_loss = 0 \n",
    "    \n",
    "    for idx, (data, age, gender) in enumerate(data_loader):\n",
    "        \n",
    "      if torch.cuda.is_available():\n",
    "          data = data.cuda()\n",
    "          age = age.cuda()\n",
    "          gender = gender.cuda()\n",
    "          \n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      \n",
    "      # get output from data \n",
    "      out_gen,out_age = model(data)\n",
    "      \n",
    "      # calculate loss and gradient \n",
    "      loss_gen = criterion_gender(out_gen, gender) # solving age problem\n",
    "      loss_age = criterion_age(out_age,age)\n",
    "      loss = gen_weight*loss_gen + (1-gen_weight)*loss_age\n",
    "      loss.backward()\n",
    "      running_loss.append(loss.item())\n",
    "      running_acc.append(accuracy(out_age,out_gen,age,gender))\n",
    "      run_ind += 1\n",
    "      total_acc += accuracy(out_age,out_gen,age,gender) * (data.size(0)/len(train_dataset))\n",
    "      total_loss += loss.item() * (data.size(0)/len(train_dataset))\n",
    "\n",
    "      \n",
    "      # adjust learning weights \n",
    "      optimizer.step()\n",
    "\n",
    "      if (idx+1) % 32 == 0:\n",
    "          print(f\"epoch:{epoch},run:{run_ind}/{len(train_loader)},loss:{round(np.sum(running_loss)/len(running_loss),4)},Acc:{round(np.sum(running_acc)/len(running_acc),4)}\")\n",
    "          running_loss = []\n",
    "          running_acc = []\n",
    "            \n",
    "    print(\"##################\")\n",
    "    print(f\"Epoch {epoch}, Train Accuracy {round(total_acc,4)},Train Loss {round(total_loss,4)}\")\n",
    "    return total_acc, total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94219f0",
   "metadata": {},
   "source": [
    "### Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f098a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(epoch, val_loader, model, criterion_age,criterion_gender,gen_weight=0.5):\n",
    "    # evaluation loop\n",
    "    \n",
    "\n",
    "    for idx, (data, age, gender) in enumerate(val_loader):\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            age = age.cuda()\n",
    "            gender = gender.cuda()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            out_gen,out_age = model(data)\n",
    "            loss_gen = criterion_gender(out_gen, gender) # solving age problem\n",
    "            loss_age = criterion_age(out_age,age)\n",
    "            loss = gen_weight*loss_gen + (1-gen_weight)*loss_age\n",
    "            \n",
    "            acc = accuracy(out_age,out_gen,age,gender)\n",
    "            \n",
    "\n",
    "    print(f\"Epoch {epoch}, Val Accuracy {round(acc,4)}, Val Loss {round(loss.item(),4)}\")\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8ec0ff",
   "metadata": {},
   "source": [
    "### Setup\n",
    "The validation set is going through in one big batch. The model must be put on the device. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6fe05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_specs,train_ages,train_gens)\n",
    "dev_dataset = MyDataset(dev_specs,dev_ages,dev_gens)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset,batch_size=len(dev_dataset),shuffle=False)\n",
    "\n",
    "# define model\n",
    "model = GenderAgeattnModel().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad237bf6",
   "metadata": {},
   "source": [
    "Sanity check on training batches and dimensions 64x3x128x128 = Batch x Channels x Height x Width..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92f8d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = iter(train_loader)\n",
    "example_data,example_age,example_gender= examples.next()\n",
    "example_data.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dad242",
   "metadata": {},
   "source": [
    "### Imbalance \n",
    "Implemented \"Class-Balanced Loss Based on Effective Number of Samples\" Cui et al (2019). This is nice weighting scheme based on marginal utility of data for each class which will be used to bias the loss functions. The weights calculate dmust go to the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a52b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reweight(cls_num_list, beta=0.999):\n",
    "    \"\"\"\n",
    "    Takes a list of frequencies of all classes and returns a list of weights \n",
    "    per class taking into accout class balanced loss and focal loss \n",
    "    \n",
    "    Args:\n",
    "        cls_num_list: # of each class in training \n",
    "        beta = hyperparameter usually N-1/N \n",
    "\n",
    "    Returns:\n",
    "        per_cls_weights = a list of all weights \n",
    "    \"\"\"\n",
    "    per_cls_weights = None\n",
    "    result = []\n",
    "    normed = []\n",
    "    C = len(cls_num_list)\n",
    "    for i in range(C):\n",
    "        result.append((1-beta)/(1-beta**cls_num_list[i]))\n",
    "    normalize = np.sum(result) * (1/C)\n",
    "    for i in range(C):\n",
    "        normed.append(result[i]/normalize)\n",
    "    per_cls_weights = normed\n",
    "\n",
    "    return per_cls_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c0b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class frequency\n",
    "count_age = list(dict(Counter(train_ages)).items())\n",
    "sorted_age = [y for (x,y) in sorted(count_age, key=lambda x: x[0], reverse=False)]\n",
    "count_gens = list(dict(Counter(train_gens)).items())\n",
    "sorted_gens = [y for (x,y) in sorted(count_gens, key=lambda x: x[0], reverse=False)]\n",
    "\n",
    "# weightings \n",
    "per_cls_weights_age = torch.Tensor(reweight(sorted_age)).to(device)\n",
    "per_cls_weights_gender = torch.Tensor(reweight(sorted_gens)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5419caf",
   "metadata": {},
   "source": [
    "For this case we have imbalance but it isn't dramatic, so the weighting are just slight nudges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89216a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_cls_weights_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb7ebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_cls_weights_age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265fedb8",
   "metadata": {},
   "source": [
    "### Loss Functions \n",
    "One each, with the weighting schemes included. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd3d57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criteria\n",
    "criterion_age = nn.CrossEntropyLoss(weight=per_cls_weights_age)\n",
    "criterion_gender = nn.CrossEntropyLoss(weight=per_cls_weights_gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce05f5e8",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2427381f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0007\n",
    "weight_decay = 0.0005\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay=weight_decay) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fc5f42",
   "metadata": {},
   "source": [
    "### Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a181519",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_accs = []    \n",
    "tr_losses = []\n",
    "val_accs = []\n",
    "val_losses = []\n",
    "\n",
    "epochs = 10\n",
    "for epoch in list(range(epochs)):\n",
    "    tr_acc, tr_loss = train(epoch, train_loader, model, optimizer, criterion_age,criterion_gender)\n",
    "    val_acc, val_loss = validate(epoch, test_loader, model, criterion_age,criterion_gender)\n",
    "    tr_accs.append(tr_acc)\n",
    "    tr_losses.append(tr_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2883a9a2",
   "metadata": {},
   "source": [
    "### Comments\n",
    "This isn't the best model, just an early one. This will run in a few hours on the 20,000 + datapoints I used to train, but as it need to be tuned, the CPU becomes impossible. With 137,000,000 parameters, tuning over a modest 64 hyperparameter combinations is at approx 6 hours on a single GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cda1ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
